"""Ollama client for handling interactions with the Ollama API."""

import json
import typing
from typing import Any

import httpx
from pydantic import ValidationError

from config import settings
from src.core.schemas import HabitAdvice
from src.utils.logger import setup_logger

logger = setup_logger(__name__)
POST_REQUEST_TIMEOUT = 90


class AIClient:
    """Generic AI client interface for handling interactions with AI models."""

    def __init__(self, model: str, base_url: str, endpoint_url: str) -> None:
        self.model = model
        self.base_url = base_url
        self.endpoint_url = endpoint_url
        self._client: httpx.AsyncClient | None = None

    async def __aenter__(self) -> "AIClient":
        """Initializes the HTTP client for making requests to the AI API."""
        if self._client is None:
            self._client = httpx.AsyncClient(timeout=POST_REQUEST_TIMEOUT)
        return self

    async def __aexit__(self, exc_type: type[BaseException] | None, exc: BaseException | None, tb: typing.Any) -> None:
        """Closes the HTTP client to free up resources after use."""
        if self._client:
            await self._client.aclose()
            self._client = None

    async def _post_request(self, payload: dict[str, Any], url: str) -> str:
        """
        Generic POST method for all AI models.

        :payload: The payload to be sent in the POST request, containing the model and
        messages for the AI request
        :url: The URL endpoint for the AI API to which the POST request will be sent
        e.g. for Ollama API, it would be "http://localhost:11434/api/chat"
        :return: The content of the response from the AI API as a string
        """
        if not self._client:
            raise RuntimeError("Client not initialized. Use 'async with'!")
        logger.info(f"Sending POST request to AI API at {url} with payload: {payload}")
        response = await self._client.post(url=url, json=payload)
        response.raise_for_status()
        logger.info(f"Received response from AI API: {response.text}")
        return str(response.json()["message"]["content"])

    def _build_payload(self, system_prompt: str, user_prompt: str) -> dict[str, Any]:
        """
        Builds the payload for the POST request to the AI model.
        'stream' is set to False to get the full response in one go, and
        'format' is set to 'json' to ensure the response is in JSON format for
        easier parsing.

        :system_prompt: The system prompt to guide the AI's response
        :user_prompt: The user prompt containing the specific question or request for the AI
        :return: A dictionary containing the model and messages for the AI request
        """
        return {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            "stream": False,
            "format": "json",
        }

    async def _get_habit_advice(self, system_prompt: str, user_prompt: str) -> HabitAdvice:
        """
        Gets habit advice from the AI model based on the provided payload.

        :system_prompt: The system prompt to guide the AI's response
        :user_prompt: The user prompt containing the specific question or request for the AI
        :return: HabitAdvice object containing the advice generated by the AI model
        """
        payload = self._build_payload(system_prompt, user_prompt)
        raw_content = await self._post_request(payload, self.endpoint_url)
        return HabitAdvice.model_validate_json(raw_content)


class OllamaClient(AIClient):
    """Ollama client for handling interactions with the Ollama API."""

    def __init__(self, model: str = "llama3.1:latest"):
        self.model = model
        self.base_url = settings.OLLAMA_URL if settings.OLLAMA_URL else "http://localhost:11434"
        self.chat_url = f"{self.base_url}/api/chat"
        super().__init__(model=self.model, base_url=self.base_url, endpoint_url=self.chat_url)

    async def get_habit_advice(self, habit_name: str, streak: int, days_missed: int) -> HabitAdvice | None:
        """
        Creates the habit advice based on response from the AI model

        :habit_name: The name of the habit for which advice is being sought
        :streak: The current streak of the user for the habit
        :days_missed: The number of days the user has missed maintaining the habit
        :return: HabitAdvice or None
        """
        system_prompt = (
            "You are a Senior Behavioral Coach. Provide a specific, actionable tip "
            "for a user who is struggling to maintain their habit streak. "
            "Return the response ONLY as a JSON object with keys: "
            "'habit_name', 'reasoning', 'advice_tip', and 'priority'."
        )
        user_prompt = (
            f"The user is struggling to maintain their habit: {habit_name}. "
            f"Their current streak is {streak} and they have missed {days_missed} days."
        )
        logger.info(f"Getting habit advice from Ollama API at {self.chat_url}")
        try:
            async with self:
                habit_advice = await self._get_habit_advice(system_prompt, user_prompt)
                logger.info(f"Received habit advice from Ollama API: {habit_advice}")
                return habit_advice
        except httpx.HTTPStatusError as err:
            logger.error(f"HTTP error {err.response.status_code}: {err.response.text}")
        except httpx.RequestError as err:
            logger.error(f"Error during execution of request: {err}")
        return None

    async def get_general_coaching(self, user_context: dict[str, Any]) -> HabitAdvice | None:
        """
        Gets general coaching advice based on the user's overall context, including
        their habits and profile information.

        :user_context: A dictionary containing user profile and habit information to
        provide context for the AI's advice generation
        :return: HabitAdvice or None
        """
        system_prompt = (
            "You are a Strategic Life Architect. Analyze the user's entire profile and "
            "habit history to identify patterns, strengths, and areas for improvement. "
            "Provide one high-level strategic tip to help them achieve better consistency. "
            "Return the response ONLY as a JSON object with keys: "
            "'habit_name', 'reasoning', 'advice_tip', and 'priority'."
        )
        user_prompt = f"Provide a strategic analysis for this user. User context and habit data: {user_context}."
        logger.info(f"Getting habit advice from Ollama API at {self.chat_url}")
        try:
            async with self:
                habit_advice = await self._get_habit_advice(system_prompt, user_prompt)
                logger.info(f"Received habit advice from Ollama API: {habit_advice}")
                return habit_advice
        except httpx.HTTPStatusError as err:
            logger.error(f"HTTP error {err.response.status_code}: {err.response.text}")
        except httpx.RequestError as err:
            logger.error(f"Error during execution of request: {err}")
        except ValidationError as err:
            logger.error(f"Error validating response from Ollama API: {err}")
        return None

    async def generate_tags(self, habit_name: str, habit_description: str) -> str:
        """
        Generate the tags based on user input for given habit name with description

        :habit_name: The name of the habit for which tags are being generated
        :habit_description: The description of the habit for which tags are being generated
        :return: A string of comma-separated tags
        """
        system_prompt = (
            "You are a productivity expert. Analyze the habit and return 3-5 relevant "
            "tags as a JSON object with a single key 'tags' containing a comma-separated string. "
            "Example: {'tags': 'health, fitness, morning'}"
        )
        user_prompt = f"Habit: {habit_name}. Description: {habit_description}."
        logger.info(f"Getting habit tags from Ollama API at {self.chat_url}")
        try:
            async with self:
                raw_content = await self._post_request(
                    self._build_payload(system_prompt, user_prompt), self.endpoint_url
                )
                tags_dict = json.loads(raw_content)
                return typing.cast(str, tags_dict.get("tags", ""))
        except httpx.HTTPStatusError as err:
            logger.error(f"HTTP error {err.response.status_code}: {err.response.text}")
        except httpx.RequestError as err:
            logger.error(f"Error during execution of request: {err}")
        return ""
